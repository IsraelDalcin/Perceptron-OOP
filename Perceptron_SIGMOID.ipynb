{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1015,
      "id": "89407d01-ea37-45aa-a753-7421d9f78dc5",
      "metadata": {
        "tags": [],
        "id": "89407d01-ea37-45aa-a753-7421d9f78dc5"
      },
      "outputs": [],
      "source": [
        "# Librarys\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "SEED = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1016,
      "id": "e4155275-0d29-4b2a-bda0-fa28b687fc2e",
      "metadata": {
        "tags": [],
        "id": "e4155275-0d29-4b2a-bda0-fa28b687fc2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3add40a5-9365-49e0-ed12-1e095f4ed0d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([ 446, 1054]))\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(SEED)\n",
        "# Generating our DataBase using Random numbers, Randomizing numbers between 0 and 1. 1 represents 'yes' and 0 represents 'no'\n",
        "proportion1 = 0.7\n",
        "proportion2 = 0.3\n",
        "# I am providing a skewed distribution to the model to capture potential patterns\n",
        "X = np.random.choice([0, 1], size=(500, 3), p=[1 - proportion1, proportion1])\n",
        "y = np.random.choice([0, 1], size=(500, 1), p=[1 - proportion2, proportion2])\n",
        "#X\n",
        "print(np.unique(X, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1017,
      "id": "6a0bc98c-8665-4cc6-9312-23efad27c157",
      "metadata": {
        "tags": [],
        "id": "6a0bc98c-8665-4cc6-9312-23efad27c157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf01f14b-bfda-4748-8ad3-a5baf4383584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([351, 149]))\n"
          ]
        }
      ],
      "source": [
        "#y\n",
        "print(np.unique(y, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1018,
      "id": "feddfe6c-321d-4405-9179-1a971a115aae",
      "metadata": {
        "tags": [],
        "id": "feddfe6c-321d-4405-9179-1a971a115aae"
      },
      "outputs": [],
      "source": [
        "# Creating a class for the Neuron. This neuron will have a list with weights and BIAS\n",
        "class Neuron:\n",
        "    def __init__(self):\n",
        "        self.features = None\n",
        "        self.neurons = None\n",
        "\n",
        "    # We need to use the features as parameters to know how many weights we will have and the number of neurons to determine the quantity of BIAS\n",
        "    # As we are using a Perceptron, evidently, we will have only one neuron, so the BIAS will have only one value assigned to that neuron\n",
        "    # It was necessary to create the object without parameters and then add them later in a loop structure, so we needed to create a function to assign the attributes as parameters\n",
        "    def values_assignment(self, features, neurons):\n",
        "        self._weights = np.zeros(len(features))\n",
        "        self._bias = np.zeros(neurons)\n",
        "\n",
        "    # Add the value for the respective Weight\n",
        "    def add_weights(self, index_cols, delta_wj):\n",
        "        self._weights[index_cols] = self._weights[index_cols] + delta_wj\n",
        "\n",
        "    def add_bias(self, delta_bias):\n",
        "        self._bias[0] = self._bias[0] + delta_bias\n",
        "\n",
        "    # Our sigmoid function\n",
        "    def sigmoid(self, x):\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Checking the activation of the Neuron with a Step Function\n",
        "    def activation_check(self, features, output):\n",
        "        threshold = 0.8\n",
        "        # Weighted sum to input into our activation function\n",
        "        weighted_sum = (np.dot(features, self._weights) + self._bias)\n",
        "        # Activation function using our Weighted sum\n",
        "        sigmoid_function = self.sigmoid(weighted_sum)\n",
        "        # If the result is greater than threshold, so the Neuron activate\n",
        "        if sigmoid_function > threshold:\n",
        "            self.checking_prediction = 1\n",
        "            if self.checking_prediction == output:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        else:\n",
        "            self.checking_prediction = 0\n",
        "            if self.checking_prediction == output:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "\n",
        "    def __str__(self):\n",
        "        return f'Weights: {self._weights} | BIAS: {self._bias}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1019,
      "id": "c43e655b-c829-48b9-afdc-40c3ef102b78",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c43e655b-c829-48b9-afdc-40c3ef102b78",
        "outputId": "98de9986-5457-465d-90c2-e135aa2c6b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1018-0d49cdf98921>:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self._weights[index_cols] = self._weights[index_cols] + delta_wj\n",
            "<ipython-input-1018-0d49cdf98921>:19: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self._bias[0] = self._bias[0] + delta_bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 12500\n",
            "Prediction: 7425\n",
            "Accuracy of the train model: 59.40%\n"
          ]
        }
      ],
      "source": [
        "# Instantiating the object neuron\n",
        "neuron = Neuron()\n",
        "# The learning rate constant\n",
        "η = 0.08\n",
        "# Used these variables to calculate the accuracy of the model\n",
        "trys = 0\n",
        "corrects = 0\n",
        "\n",
        "for i in range(25):\n",
        "  # Creating a Loop to walk through the vector X\n",
        "  for index_row, row in enumerate(X):\n",
        "      trys += 1\n",
        "      # Checking if is the 1st time of the loop, if yes, we create the weights based on ours features\n",
        "      if index_row == 0:\n",
        "          neuron.values_assignment(row, 1)\n",
        "\n",
        "      # Calling the method 'activation_check' to instance the attribute \"checking_prediction\"\n",
        "      neuron.activation_check(row, y[index_row])\n",
        "\n",
        "      # Here is where our perceptron works\n",
        "      # 1st we are checking if the neuron DON'T activade, if Don't, it means we need fit the Weights\n",
        "      if neuron.activation_check(row, y[index_row]) == False:\n",
        "          # Loop to walk through the columns, so we can calculate the weights for each feature specifically\n",
        "          for index_col, col in enumerate(row):\n",
        "                  # Using the basic function of perceptrons to calculate the weights\n",
        "                  delta_wj = η * (y[index_row] - neuron.checking_prediction) * col\n",
        "                  # This part call the method \"add_weights\" to add the weight on the respective index of the weight vector\n",
        "                  neuron.add_weights(index_col, delta_wj)\n",
        "          '''I needed to work with the BIAS separately from the weights, to be able to calculate it independently. However, the function remains the same, with the only change being in X[0]\n",
        "          as the bias will always be 1'''\n",
        "          delta_bias = η * (y[index_row] - neuron.checking_prediction) * 1\n",
        "          # Same with weights, just adding the bias to the BIAS vector\n",
        "          neuron.add_bias(delta_bias)\n",
        "      else:\n",
        "          corrects += 1\n",
        "\n",
        "# Accuracy mathematics\n",
        "print(f'Total: {trys}')\n",
        "print(f'Prediction: {corrects}')\n",
        "\n",
        "accuracy = corrects / trys\n",
        "print(f'Accuracy of the train model: {accuracy*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1020,
      "id": "c605570b-88ff-4d0e-a4d2-0a74efd297db",
      "metadata": {
        "id": "c605570b-88ff-4d0e-a4d2-0a74efd297db"
      },
      "outputs": [],
      "source": [
        "# Creating our test dataset to validate the model\n",
        "SEED = 15\n",
        "np.random.seed(SEED)\n",
        "X_test = np.random.choice([0, 1], size=(500, 3), p=[1 - proportion1, proportion1])\n",
        "y_test = np.random.choice([0, 1], size=(500, 1), p=[1 - proportion2, proportion2])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The distribuition of 0 and 1 in X_test\n",
        "print(np.unique(X_test, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzSnAdlR3hU0",
        "outputId": "fb77d42c-b934-46c2-b157-378dae12f946"
      },
      "id": "MzSnAdlR3hU0",
      "execution_count": 1021,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([ 438, 1062]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Idem for Y\n",
        "print(np.unique(y_test, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdGaAZTv3oTD",
        "outputId": "02b2d061-4242-4703-a6f8-cf2f36f5111f"
      },
      "id": "ZdGaAZTv3oTD",
      "execution_count": 1022,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([343, 157]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trys_test = 0\n",
        "corrects_test = 0\n",
        "dummy_predictions = 0\n",
        "\n",
        "# Same logic used in the cell above, but here I am predicting Y based on a new test dataset that we also randomly selected values for.\n",
        "for index_row, row in enumerate(X_test):\n",
        "    trys_test += 1\n",
        "\n",
        "    neuron.activation_check(row, y_test[index_row])\n",
        "\n",
        "    if neuron.checking_prediction:\n",
        "      if neuron.checking_prediction == y_test[index_row]:\n",
        "        corrects_test += 1\n",
        "\n",
        "    else:\n",
        "      if neuron.checking_prediction == y_test[index_row]:\n",
        "        dummy_predictions += 1\n",
        "        corrects_test += 1\n",
        "\n",
        "\n",
        "\n",
        "# Accuracy mathematics\n",
        "print(f'Total: {trys_test}')\n",
        "print(f'Prediction: {corrects_test}')\n",
        "\n",
        "accuracy_test = corrects_test / trys_test\n",
        "dummy_accuracy_test = dummy_predictions / trys_test\n",
        "\n",
        "print(f'The prediction accuracy of the DUMMY model was: {dummy_accuracy_test*100}%')\n",
        "print(f'The prediction accuracy of the PERCEPTRON model was: {accuracy_test*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IiGxgYZ-El1",
        "outputId": "f8d2b182-4cbe-4e95-a140-8e596a36330e"
      },
      "id": "7IiGxgYZ-El1",
      "execution_count": 1023,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 500\n",
            "Prediction: 308\n",
            "The prediction accuracy of the DUMMY model was: 54.0%\n",
            "The prediction accuracy of the PERCEPTRON model was: 61.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LHm6fxI7_GN7"
      },
      "id": "LHm6fxI7_GN7",
      "execution_count": 1023,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}